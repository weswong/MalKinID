{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv, read_excel\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import sys\n",
    "import itertools\n",
    "import time\n",
    "import scipy.stats \n",
    "from sklearn.neighbors import KernelDensity\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import copy\n",
    "import dill\n",
    "import matplotlib.patches as mpatches\n",
    "import copy\n",
    "\n",
    "\n",
    "chr_lengths= {1: 643000,\n",
    "                         2: 947000,\n",
    "                         3: 1100000,\n",
    "                         4: 1200000,\n",
    "                         5: 1350000,\n",
    "                         6: 1420000,\n",
    "                         7: 1450000,\n",
    "                         8: 1500000,\n",
    "                         9: 1550000,\n",
    "                         10: 1700000,\n",
    "                         11: 2049999,\n",
    "                         12: 2300000,\n",
    "                         13: 2950000,\n",
    "                         14: 3300000}\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "                            np.int16, np.int32, np.int64, np.uint8,\n",
    "                            np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32,\n",
    "                              np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.ndarray,)):  #### This is the fix\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "cpalette1 = sns.color_palette('Reds_r', 2)\n",
    "cpalette2 = sns.color_palette('Blues_r', 3)\n",
    "cpalette3 = sns.color_palette('Greys_r', 3)\n",
    "\n",
    "color_map_dict = {'PC': cpalette1[0],\n",
    "                 'FS': cpalette1[1],\n",
    "                 'MS': cpalette1[1],\n",
    "                 'GC': cpalette2[0],\n",
    "                 'HS': cpalette2[1],\n",
    "                  'FAV': cpalette2[2],\n",
    "                  'GGC': cpalette3[0],\n",
    "                  'HAV': cpalette3[1],\n",
    "                  'FCS': cpalette3[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7517ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_results(pattern, metric):\n",
    "    if metric != 'r_totals':\n",
    "        combined_dict = defaultdict(lambda: defaultdict(list))\n",
    "    else:\n",
    "        combined_dict = defaultdict(list)\n",
    "    for file in glob.glob(pattern):\n",
    "        file_dict = json.load(open(file))\n",
    "        for relationship in file_dict:\n",
    "            if metric != 'r_totals':\n",
    "                for chrom in file_dict[relationship]:\n",
    "                    for segment_lengths in file_dict[relationship][chrom]:\n",
    "                        combined_dict[relationship][chrom].append(segment_lengths)\n",
    "            else:\n",
    "                combined_dict[relationship] += file_dict[relationship]\n",
    "    return combined_dict\n",
    "\n",
    "\n",
    "def combine_sims(directory,basename):\n",
    "    fs_file_patterns = ['*_ibd_segment_numbers.json', \n",
    "                        '*_ibd_segment_max.json',\n",
    "               '*_r_totals.json']\n",
    "    combined_dicts = {}\n",
    "    for pattern in fs_file_patterns:\n",
    "        match = re.search('/*_(.+).json',pattern)\n",
    "        metric = match.groups()[0]\n",
    "        print(metric)\n",
    "        combined_dicts[metric] = combine_results(directory + pattern, metric)\n",
    "        json.dump(combined_dicts[metric], \n",
    "                  open(directory + '{b}_{m}_combined.json'.format(m=metric,b=basename), 'w'), cls = NumpyEncoder)\n",
    "    \n",
    "combine_sims('sims/outcross_tx_chain/', basename = 'outcross_chain')\n",
    "combine_sims('sims/serial_cotx_chain/', basename = 'serial_cotx_chain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90cf6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sim_dict = defaultdict(dict)\n",
    "for sim_type in ['serial_cotx_chain']:\n",
    "    sim_dict[sim_type]['r_totals'] = json.load(open('sims/{p}/serial_cotx_chain_r_totals_combined.json'.format(p=sim_type)))\n",
    "    sim_dict[sim_type]['ibd_segment_max'] = json.load(open('sims/{p}/serial_cotx_chain_ibd_segment_max_combined.json'.format(p=sim_type)))\n",
    "    sim_dict[sim_type]['ibd_segment_numbers'] = json.load(open('sims/{p}/serial_cotx_chain_ibd_segment_numbers_combined.json'.format(p=sim_type)))\n",
    "    max_segment_p_dict = defaultdict(dict)\n",
    "    for relationship in sim_dict[sim_type]['ibd_segment_max']:\n",
    "        for chrom in sim_dict[sim_type]['ibd_segment_max'][relationship]:\n",
    "            max_segment_p_dict[relationship][chrom] = np.asarray([x for x in np.asarray(sim_dict[sim_type]['ibd_segment_max'][relationship][chrom]) / chr_lengths[int(chrom)]])\n",
    "    sim_dict[sim_type]['p_ibd_max'] = max_segment_p_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f11f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#focus_nodes = ['P1', 'F1', 'F2', 'F3', 'F4']\n",
    "focus_comparisons = {'P1.F1':'PC', 'P1.F12':'PC', 'P2.F1':'PC', 'P2.F12':'PC',\n",
    "                    'F1.F2':'PC', 'F1.F22':'PC', 'A1.F2':'PC', 'A1.F22':'PC',\n",
    "                     'F2.F3':'PC', 'F2.F32':'PC', 'A3.F3':'PC', 'A3.F32':'PC',\n",
    "                     'F1.F12':'FS', 'F2.F22':'FS','F3.F32':'FS',\n",
    "                    'P1.F2':'GC', 'P1.F22':'GC', 'P2.F2':'GC', 'P2.F22':'GC',\n",
    "                    'A1.F3':'GC', 'A1.F32':'GC', 'F1.F3':'GC', 'F1.F32':'GC',\n",
    "                    'F12.F2': 'FAV', 'F12.F22':'FAV', 'F12.F3':'FAV', 'F22.F32':'FAV',\n",
    "                    'P1.F3':'GGC', 'P2.F3':'GGC', 'P1.F32':'GGC','P2.F32':'GGC'}\n",
    "\n",
    "simulated_M_dict = defaultdict(list)\n",
    "\n",
    "for comparison in sim_dict['serial_cotx_chain']['p_ibd_max'].keys():\n",
    "    ibd_segment_count_M = np.asarray([sim_dict['serial_cotx_chain']['ibd_segment_numbers'][comparison][str(key)] for key in range(1,15)]).T\n",
    "    p_ibd_segment_M = np.asarray([sim_dict['serial_cotx_chain']['p_ibd_max'][comparison][str(key)] for key in range(1,15)]).T\n",
    "    #sample x chromosome\n",
    "\n",
    "    idx = 0\n",
    "    for relatedness, ibd_segment_count_v, p_ibd_segment_v in zip(sim_dict['serial_cotx_chain']['r_totals'][comparison],\n",
    "                                                                ibd_segment_count_M,\n",
    "                                                                p_ibd_segment_M):\n",
    "        name = str(idx)\n",
    "        simulated_M_dict[comparison].append([name, relatedness]  + list(ibd_segment_count_v) + list(p_ibd_segment_v))\n",
    "        idx += 1\n",
    "    simulated_M_dict[comparison] = np.asarray(simulated_M_dict[comparison]).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd5bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_max_segment_piecewise_pdf(x, relationship, chrom, pdf_dict, bandwidth =0.02):\n",
    "    '''modeled as a kde with spikes'''\n",
    "    #print(fs_max_segment_pdf_dict[relationship][int(chrom)])\n",
    "    p0,p1,kde, tstep, = pdf_dict[relationship][int(chrom)]\n",
    "                       \n",
    "    if float(x) <= 0 + bandwidth:\n",
    "        return p0/tstep\n",
    "    elif float(x) >= 1 - bandwidth:\n",
    "        return p1/tstep\n",
    "    else:\n",
    "        x_transmute = np.asarray([x])\n",
    "        #if beta_dis:\n",
    "        #    pdf = scipy.stats.beta.pdf(x, alpha, beta, loc, scale)\n",
    "        #else:\n",
    "        pdf = np.exp(kde.score_samples(x_transmute.reshape(-1,1)))[0]\n",
    "        pdf = pdf * (1-p0-p1)\n",
    "        return pdf\n",
    "    \n",
    "def fit_beta(relationships,):\n",
    "    beta_variables = {}\n",
    "    r_dict = raw_sim_data['fs']['r_totals']\n",
    "    for relationship in relationships:\n",
    "        print(relationship)\n",
    "        r_list = r_dict[relationship]\n",
    "        r_list = [x if x != 0 else 1e-9 for x in r_list]\n",
    "        alpha, beta, loc, scale = scipy.stats.beta.fit(r_list, floc=0,fscale=1)\n",
    "        #x = np.linspace(0, 1, 100)\n",
    "        beta_variables[relationship] = (alpha, beta, loc, scale)\n",
    "        \n",
    "    return beta_variables\n",
    "\n",
    "\n",
    "def plot_r_totals(beta_vals_dict, relationships, color_map_dict):\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    #plt.figure(figsize = (8,5))\n",
    "    i= 1\n",
    "    for relationship in relationships:\n",
    "        alpha, beta, loc, scale = beta_vals_dict[relationship]\n",
    "        pdf = scipy.stats.beta.pdf(x, alpha, beta, loc, scale)\n",
    "\n",
    "        plt.plot(x, pdf, color = color_map_dict[relationship], label = relationship)\n",
    "        plt.xlabel('Genome-wide Total Relatedness', fontsize = 15)\n",
    "        plt.ylabel('Density', fontsize = 15)\n",
    "        plt.xlim(-0.05,1.05)\n",
    "        plt.ylim(-0.05, 10)\n",
    "        plt.legend(ncols = 3, fontsize = 12)\n",
    "        plt.tick_params(axis='both', which='major', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = dill.load(open('ll_parameters_2.0_11.3_v2.pkl', 'rb'))\n",
    "degree_relationships_ms = defaultdict(list)\n",
    "degree_relationships_ms[1] = ['PC', 'FS', 'MS.MS']\n",
    "degree_relationships_ms[2] = ['GC', 'HS', 'FAV', 'FAV.MS']\n",
    "degree_relationships_ms[3] = ['GGC', 'HAV', 'FCS', 'FCS.MS']\n",
    "degree_relationships_ms['all'] = ['PC', 'GC', 'MS.MS', \n",
    "                               'GGC', 'FS', 'HS', 'FAV','FAV.MS', \n",
    "                               'HAV', 'FCS', 'FCS.MS']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Sim:\n",
    "    parental_strains = ['P1', 'P2']\n",
    "\n",
    "    def __init__(self, comparison, r_total, max_ibd_segment, n_segment_count):\n",
    "        self.comparison = comparison\n",
    "        \n",
    "        self.r_total = r_total\n",
    "\n",
    "        self.max_ibd_segment = max_ibd_segment\n",
    "        self.n_segment_count = n_segment_count\n",
    "        self.calc_all_likelihoods()\n",
    "    \n",
    "    def likelihood(self, G, r_flag = 1, ibdmax_flag = 1, count_flag = 1):\n",
    "        r_total_beta_params = pdfs['r_beta'][G]\n",
    "        logL = 0\n",
    "        P_rtotal = scipy.stats.beta.logpdf(self.r_total, *r_total_beta_params)\n",
    "        P_ibdmax = 0\n",
    "        P_seg_count = 0\n",
    "        for chrom in range(1,15):\n",
    "            idx = chrom - 1\n",
    "            P_ibdmax += np.log(evaluate_max_segment_piecewise_pdf(self.max_ibd_segment[idx], G, chrom, \\\n",
    "                                                            pdfs['p_max_segment']))\n",
    "\n",
    "            n_segments = self.n_segment_count[idx]\n",
    "            if n_segments in pdfs['segment_count'][G][str(chrom)].keys():\n",
    "                P_seg_count += np.log(pdfs['segment_count'][G][str(chrom)][n_segments])\n",
    "            else:\n",
    "                P_seg_count += np.log(pdfs['segment_count'][G][str(chrom)]['misc'])\n",
    "        logL = P_rtotal * r_flag +  P_ibdmax * ibdmax_flag + P_seg_count * count_flag\n",
    "\n",
    "        return logL\n",
    "    \n",
    "    def calc_all_likelihoods(self, r_flag = 1, ibdmax_flag = 1, count_flag = 1):       \n",
    "        self.complete_likelihoods_ms = {}\n",
    "        for G in ['PC', 'GC', 'GGC', 'FS', 'HS', 'FAV', 'HAV', 'FCS','MS.MS', 'FAV.MS', 'FCS.MS']:\n",
    "            self.complete_likelihoods_ms[G] = self.likelihood(G, r_flag, ibdmax_flag, count_flag)\n",
    "        \n",
    "        self.max_complete_likelihood_ms = max(self.complete_likelihoods_ms, key = self.complete_likelihoods_ms.get)\n",
    "        \n",
    "        self.llr = {}\n",
    "        for degree in [1,2,3]:\n",
    "            numerator_hypotheses = degree_relationships_ms[degree]\n",
    "            numerator = max([self.complete_likelihoods_ms[G] for G in degree_relationships_ms[degree]])\n",
    "            denominator_hypotheses = [G for G in degree_relationships_ms['all'] if G not in degree_relationships_ms[degree]]\n",
    "            denominator = max([self.complete_likelihoods_ms[G] for G in denominator_hypotheses])\n",
    "            self.llr[degree] = -2 * (numerator-denominator)\n",
    "            \n",
    "        self.llr_degree_classification = min(self.llr, key = self.llr.get)\n",
    "        \n",
    "        \n",
    "            \n",
    "def format_ingest_data(comparison):\n",
    "    data_dict = defaultdict(list)\n",
    "    data = simulated_M_dict[comparison]\n",
    "    n_ibd_segment_dict = {}\n",
    "    max_ibd_segment_dict = {}\n",
    "    for row in data:\n",
    "        comparison = row[0]\n",
    "        if comparison % 500 == 0:\n",
    "            print(comparison)\n",
    "        relatedness = row[1]\n",
    "        n_ibd_segments = row[2:16]\n",
    "        max_ibd_segments = row[16:]\n",
    "        #for chrom, n_ibd, max_ibd in zip(range(1,15), n_ibd_segments, max_ibd_segments):\n",
    "        #    n_ibd_segment_dict[chrom] = n_ibd\n",
    "        #    max_ibd_segment_dict[chrom] = max_ibd\n",
    "        #print(comparison)\n",
    "        #print(relatedness, n_ibd_segments, max_ibd_segments)\n",
    "        S = Sim(comparison, relatedness,max_ibd_segments, n_ibd_segments)\n",
    "        #print(S.complete_likelihoods_ms)\n",
    "        data_dict[comparison]= S\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7371c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_relationships_ms = defaultdict(list)\n",
    "degree_relationships_ms[1] = ['PC', 'FS', 'MS.MS']\n",
    "degree_relationships_ms[2] = ['GC', 'HS', 'FAV', 'FAV.MS']\n",
    "degree_relationships_ms[3] = ['GGC', 'HAV', 'FCS', 'FCS.MS']\n",
    "degree_relationships_ms['all'] = ['PC', 'GC', 'MS.MS', \n",
    "                               'GGC', 'FS', 'HS', 'FAV','FAV.MS', \n",
    "                               'HAV', 'FCS', 'FCS.MS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6041f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_M_dict = {}\n",
    "for comparison in simulated_M_dict:\n",
    "    print(comparison)\n",
    "    likelihood_M_dict[comparison] = format_ingest_data(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00278bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}\n",
    "first_degree_nodes = ['P1.F11', 'P2.F11', 'P1.F12', 'P2.F12',\n",
    "                     'F11.F21', 'F11.F22', 'F12.F21', 'F12.F22',\n",
    "                     'F21.F31', 'F21.F32', 'F22.F31', 'F22.F32',\n",
    "                     'F11.F12', 'F21.F22', 'F31.F32']\n",
    "\n",
    "pc_nodes = ['P1.F11', 'P2.F11', 'P1.F12', 'P2.F12',\n",
    "             'F11.F21', 'F11.F22', 'F12.F21', 'F12.F22',\n",
    "             'F21.F31', 'F21.F32', 'F22.F31', 'F22.F32',]\n",
    "\n",
    "fs_nodes = ['F11.F12', 'F21.F22', 'F31.F32']\n",
    "\n",
    "\n",
    "second_degree_nodes = ['P1.F21', 'P1.F22', 'P2.F21', 'P2.F22',\n",
    "                       'F11.F31', 'F12.F31', 'F11.F32', 'F12.F32',]\n",
    "third_degree_nodes = ['P1.F31', 'P1.F32','P2.F31', 'P2.F32']\n",
    "\n",
    "nodes_dict = {1: first_degree_nodes,\n",
    "             'PC': pc_nodes,\n",
    "             'FS': fs_nodes,\n",
    "              2: second_degree_nodes,\n",
    "              3: third_degree_nodes,\n",
    "        }\n",
    "\n",
    "\n",
    "for node in first_degree_nodes:\n",
    "    answers[node] =1\n",
    "for node in second_degree_nodes:\n",
    "    answers[node] = 2\n",
    "for node in third_degree_nodes:\n",
    "    answers[node] = 3\n",
    "focus_comparisons = first_degree_nodes + second_degree_nodes + third_degree_nodes\n",
    "\n",
    "answers2 = {}\n",
    "for node in pc_nodes:\n",
    "    answers2[node] = 'PC'\n",
    "for node in fs_nodes:\n",
    "    answers2[node] = 'FS'\n",
    "for node in second_degree_nodes:\n",
    "    answers2[node] = '2'\n",
    "for node in third_degree_nodes:\n",
    "    answers2[node] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_swap_dict = {}\n",
    "for G in degree_relationships_ms[2]:\n",
    "    node_swap_dict[G] = '2'\n",
    "for G in degree_relationships_ms[3]:\n",
    "    node_swap_dict[G] = '3'\n",
    "for G in degree_relationships_ms[1]:\n",
    "    node_swap_dict[G] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a328ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_relationships_ms = defaultdict(list)\n",
    "degree_relationships_ms[1] = ['PC', 'FS', 'MS.MS']\n",
    "degree_relationships_ms[2] = ['GC', 'HS', 'FAV', 'FAV.MS']\n",
    "degree_relationships_ms[3] = ['GGC', 'HAV', 'FCS', 'FCS.MS']\n",
    "degree_relationships_ms['all'] = ['PC', 'GC', 'MS.MS', \n",
    "                               'GGC', 'FS', 'HS', 'FAV','FAV.MS', \n",
    "                               'HAV', 'FCS', 'FCS.MS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ebcbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "reorganized_likelihood_M = []\n",
    "for _ in range(2500):\n",
    "    max_likelihood_calculations = [likelihood_M_dict[node][_].llr_degree_classification for node in likelihood_M_dict.keys()]\n",
    "    reorganized_likelihood_M.append(max_likelihood_calculations)\n",
    "reorganized_likelihood_M = np.asarray(reorganized_likelihood_M)\n",
    "\n",
    "reorganized_likelihood_df = DataFrame(reorganized_likelihood_M, columns =likelihood_M_dict.keys())\n",
    "\n",
    "reorganized_likelihood_M2 = []\n",
    "for _ in range(2500):\n",
    "    max_likelihood_calculations = [node_swap_dict[likelihood_M_dict[node][_].max_complete_likelihood_ms] for node in likelihood_M_dict.keys()]\n",
    "    reorganized_likelihood_M2.append(max_likelihood_calculations)\n",
    "reorganized_likelihood_M2 = np.asarray(reorganized_likelihood_M2)\n",
    "reorganized_likelihood_df2 = DataFrame(reorganized_likelihood_M2, columns =likelihood_M_dict.keys())\n",
    "reorganized_likelihood_df2.to_excel('serial_inbreeding_likelihood_categories.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "unrelated = ['P1.P2','P1.A1','P1.A2','P1.A3', \n",
    "             'P2.A1', 'P2.A2', 'P2.A3', \n",
    "             'A1.A2' 'A1.A3', 'A1.F1','A1.F12', 'A2.A3',\n",
    "            'A2.F1', 'A3.F12', 'A2.F2', 'A2.F22', 'A2.F4',\n",
    "            'A2.F42','A1.A2', 'A1.A3', 'A2.F12', 'A3.F1',\n",
    "            'A3.F2', 'A3.F22', 'A3.F3', 'A3.F32']\n",
    "\n",
    "mod_degree_relationships_ms = defaultdict(list)\n",
    "mod_degree_relationships_ms[1] = ['PC', 'FS', 'MS.MS']\n",
    "mod_degree_relationships_ms[2] = ['GC', 'HS', 'FAV', 'FAV.MS','2',2]\n",
    "mod_degree_relationships_ms[3] = ['GGC', 'HAV', 'FCS', 'FCS.MS','3',3]\n",
    "mod_degree_relationships_ms['all'] = ['PC', 'GC', 'MS.MS', \n",
    "                               'GGC', 'FS', 'HS', 'FAV','FAV.MS', \n",
    "                               'HAV', 'FCS', 'FCS.MS','2','3','1',1,2,3]\n",
    "mod_degree_relationships_ms['PC'] = ['PC']\n",
    "mod_degree_relationships_ms['FS'] = ['FS']\n",
    "\n",
    "class Diagnostic_Stats:\n",
    "    def __init__(self, degree):\n",
    "        self.degree= degree\n",
    "        self.calculate_confusion_M()\n",
    "\n",
    "    @classmethod\n",
    "    def calc_standard_error(cls,p, total):\n",
    "        return np.sqrt((p*(1-p) / total))\n",
    "    \n",
    "    def calculate_confusion_M(self):\n",
    "        degree_nodes = nodes_dict[self.degree]\n",
    "        if self.degree == int(3):\n",
    "            degree_nodes = list(nodes_dict[3]) #+ list(nodes_dict['3+'])\n",
    "        relationship_nodes = mod_degree_relationships_ms[self.degree]\n",
    "        converse_columns = [column for column in reorganized_likelihood_df2.columns if (column not in degree_nodes) & (column not in unrelated)]\n",
    "\n",
    "        TP_M = reorganized_likelihood_df2[degree_nodes].isin(relationship_nodes)\n",
    "        FN_M = ~TP_M\n",
    "\n",
    "        FP_M = reorganized_likelihood_df2[converse_columns].isin(relationship_nodes)\n",
    "        TN_M = ~FP_M\n",
    "\n",
    "        self.TPC = np.sum(TP_M, axis = 1) #calculated for each simulation iteration\n",
    "        self.FPC = np.sum(FP_M, axis = 1)\n",
    "        self.FNC = np.sum(FN_M, axis = 1)\n",
    "        self.TNC = np.sum(TN_M, axis = 1)\n",
    "\n",
    "        self.sensitivity = self.TPC / (self.TPC + self.FNC) #recall\n",
    "        #print(self.TPC + self.FNC)\n",
    "        self.specificity = self.TNC / (self.TNC + self.FPC)\n",
    "        self.ppv = self.TPC / (self.TPC + self.FPC) #precision\n",
    "        self.npv = self.TNC / (self.FNC + self.TNC)\n",
    "        self.f1 = 2*self.TPC / (2*self.TPC + self.FPC + self.FNC)\n",
    "        \n",
    "        self.youdens_J = self.sensitivity + self.specificity - 1\n",
    "        self.MCC =  (self.TPC * self.TNC - self.FPC * self.FNC) / np.sqrt((self.TPC + self.FNC) *(self.TPC + self.FNC) *(self.TNC + self.FPC) *(self.TNC + self.FNC))\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_stats = {}\n",
    "for degree in ['PC', 'FS', 1,2,3]:\n",
    "    diagnostic_stats[degree] = Diagnostic_Stats(degree)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "categories = ['PC', 'FS', 1,2,3]\n",
    "averages = [np.mean(diagnostic_stats[degree].f1) for degree in categories]\n",
    "ci_lows = [max(np.percentile(diagnostic_stats[degree].f1, 97.5) - np.mean(diagnostic_stats[degree].f1),0)  for degree in categories]\n",
    "\n",
    "ci_highs = [np.mean(diagnostic_stats[degree].f1) - np.percentile(diagnostic_stats[degree].f1, 2.5) for degree in categories]\n",
    "\n",
    "plt.bar(range(5),[np.mean(diagnostic_stats[degree].f1) for degree in categories],\n",
    "        capsize = 5, yerr = (ci_highs, ci_lows), color = [color_map_dict['PC'],\n",
    "                                                          color_map_dict['FS'], 'crimson',\n",
    "                                                          'blue', '#E2E0E0'])\n",
    "\n",
    "plt.xticks(range(5), ['PC', 'FS', '1°', '2°', '3°+'])\n",
    "\n",
    "\n",
    "\n",
    "#plt.ylim(0,1)\n",
    "plt.ylabel('F1-score', fontsize = 15)\n",
    "plt.xlabel('Genealogical Relationship', fontsize = 15)\n",
    "plt.tick_params(axis='both', labelsize = 12)\n",
    "plt.ylim(0,1)\n",
    "plt.savefig('/Users/weswong/Wirth Lab Dropbox/wes wong/MalKinID/Figures/inbred_pointimportation.svg')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
