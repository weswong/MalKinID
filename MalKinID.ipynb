{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a7df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import sys\n",
    "import itertools\n",
    "import time\n",
    "import scipy.stats \n",
    "from sklearn.neighbors import KernelDensity\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from scipy.optimize import curve_fit\n",
    "import copy\n",
    "import dill\n",
    "\n",
    "\n",
    "\n",
    "chr_lengths= {1: 643000,\n",
    "                         2: 947000,\n",
    "                         3: 1100000,\n",
    "                         4: 1200000,\n",
    "                         5: 1350000,\n",
    "                         6: 1420000,\n",
    "                         7: 1450000,\n",
    "                         8: 1500000,\n",
    "                         9: 1550000,\n",
    "                         10: 1700000,\n",
    "                         11: 2049999,\n",
    "                         12: 2300000,\n",
    "                         13: 2950000,\n",
    "                         14: 3300000}\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "                            np.int16, np.int32, np.int64, np.uint8,\n",
    "                            np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32,\n",
    "                              np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.ndarray,)):  #### This is the fix\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "cpalette1 = sns.color_palette('Reds_r', 3)\n",
    "cpalette2 = sns.color_palette('Blues_r', 3)\n",
    "cpalette3 = sns.color_palette('Greys_r', 3)\n",
    "\n",
    "color_map_dict = {'PC': cpalette1[0],\n",
    "                 'FS': cpalette1[1],\n",
    "                 'MS': cpalette1[2],\n",
    "                 'GC': cpalette2[0],\n",
    "                 'HS': cpalette2[1],\n",
    "                  'FAV': cpalette2[2],\n",
    "                  'GGC': cpalette3[0],\n",
    "                  'HAV': cpalette3[1],\n",
    "                  'FCS': cpalette3[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ff88cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = dill.load(open('ll_parameters.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba13f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_max_segment_piecewise_pdf(x, relationship, chrom, pdf_dict, bandwidth =0.02):\n",
    "    '''modeled as a kde with spikes'''\n",
    "    #print(fs_max_segment_pdf_dict[relationship][int(chrom)])\n",
    "    p0,p1,kde, tstep, = pdf_dict[relationship][int(chrom)]\n",
    "                       \n",
    "    if float(x) <= 0 + bandwidth:\n",
    "        return p0/tstep\n",
    "    elif float(x) >= 1 - bandwidth:\n",
    "        return p1/tstep\n",
    "    else:\n",
    "        x_transmute = np.asarray([x])\n",
    "        #if beta_dis:\n",
    "        #    pdf = scipy.stats.beta.pdf(x, alpha, beta, loc, scale)\n",
    "        #else:\n",
    "        pdf = np.exp(kde.score_samples(x_transmute.reshape(-1,1)))[0]\n",
    "        pdf = pdf * (1-p0-p1)\n",
    "        return pdf\n",
    "    \n",
    "def evaluate_max_segment_piecewise_pdf(x, relationship, chrom, pdf_dict, bandwidth =0.02):\n",
    "    '''modeled as a kde with spikes'''\n",
    "    #print(fs_max_segment_pdf_dict[relationship][int(chrom)])\n",
    "    p0,p1,kde, tstep, = pdf_dict[relationship][int(chrom)]\n",
    "                       \n",
    "    if float(x) <= 0 + bandwidth:\n",
    "        return p0/tstep\n",
    "    elif float(x) >= 1 - bandwidth:\n",
    "        return p1/tstep\n",
    "    else:\n",
    "        x_transmute = np.asarray([x])\n",
    "        #if beta_dis:\n",
    "        #    pdf = scipy.stats.beta.pdf(x, alpha, beta, loc, scale)\n",
    "        #else:\n",
    "        pdf = np.exp(kde.score_samples(x_transmute.reshape(-1,1)))[0]\n",
    "        pdf = pdf * (1-p0-p1)\n",
    "        return pdf\n",
    "    \n",
    "def fit_beta(r_dict):\n",
    "    beta_variables = {}\n",
    "    for relationship in r_dict:\n",
    "        r_list = r_dict[relationship]\n",
    "        r_list = [x if x != 0 else 1e-9 for x in r_list]\n",
    "        alpha, beta, loc, scale = scipy.stats.beta.fit(r_list, floc=0,fscale=1)\n",
    "        #x = np.linspace(0, 1, 100)\n",
    "        beta_variables[relationship] = (alpha, beta, loc, scale)\n",
    "        \n",
    "    return beta_variables\n",
    "\n",
    "def create_pdfs(p_max_segment_dict, bandwidth= 0.02):\n",
    "    max_segment_pdf_dict = defaultdict(dict)\n",
    "    for relationship in p_max_segment_dict:\n",
    "        for chromosome in p_max_segment_dict[relationship]:\n",
    "            data = np.asarray(p_max_segment_dict[relationship][chromosome])\n",
    "            mask0 = np.asarray(p_max_segment_dict[relationship][chromosome]) <= 0 + bandwidth\n",
    "            mask1 = np.asarray(p_max_segment_dict[relationship][chromosome]) >= 1 - bandwidth\n",
    "            mask = ~mask0 & ~mask1\n",
    "            data = np.asarray(data[mask])\n",
    "\n",
    "            p0 = (np.sum(mask0) + 1 )/ (len(mask0) + 3)\n",
    "            p1 = (np.sum(mask1) + 1 )/ (len(mask1) + 3)\n",
    "            kde = KernelDensity(kernel='gaussian',bandwidth=bandwidth).fit(data.reshape(-1,1))#training of model\n",
    "            #beta_params = scipy.stats.beta.fit(data)\n",
    "\n",
    "            max_segment_pdf_dict[relationship][int(chromosome)] =  (p0, p1, kde, bandwidth)#, beta_params)\n",
    "    return max_segment_pdf_dict\n",
    "\n",
    "def calc_seg_count_pmf(segment_counts_dict):\n",
    "    '''empirical segment_count_pmf, with add one smoothing\n",
    "    theta_i = (x_i + alpha) / (N + alpha * d)\n",
    "    where x_i is the count of the cateogory i\n",
    "    alpha is set to 1\n",
    "    d is the number of categories\n",
    "    N is the sample count'''\n",
    "    seg_count_pmf = defaultdict(lambda: defaultdict(lambda : defaultdict(dict)))\n",
    "    for relationship in segment_counts_dict:\n",
    "        for chrom in segment_counts_dict[relationship]:\n",
    "            counts = Counter(segment_counts_dict[relationship][chrom])\n",
    "            total = np.sum(list(counts.values()))\n",
    "            max_count= max(counts)\n",
    "            bins = range(0,max_count + 2) #add an additional category representing max + 1\n",
    "            n_bins = len(bins)\n",
    "            for x in bins:\n",
    "                if x in counts:\n",
    "                    seg_count_pmf[relationship][chrom][x] = (counts[x] + 1)/(total + n_bins)\n",
    "                else:\n",
    "                    seg_count_pmf[relationship][chrom]['misc'] = 1 / (total + n_bins)\n",
    "    return seg_count_pmf\n",
    "\n",
    "def evaluate_max_segment_piecewise_pdf(x, relationship, chrom, pdf_dict, bandwidth =0.02):\n",
    "    '''modeled as a kde with spikes'''\n",
    "    #print(fs_max_segment_pdf_dict[relationship][int(chrom)])\n",
    "    p0,p1,kde, tstep, = pdf_dict[relationship][int(chrom)]\n",
    "                       \n",
    "    if float(x) <= 0 + bandwidth:\n",
    "        return p0/tstep\n",
    "    elif float(x) >= 1 - bandwidth:\n",
    "        return p1/tstep\n",
    "    else:\n",
    "        x_transmute = np.asarray([x])\n",
    "        #if beta_dis:\n",
    "        #    pdf = scipy.stats.beta.pdf(x, alpha, beta, loc, scale)\n",
    "        #else:\n",
    "        pdf = np.exp(kde.score_samples(x_transmute.reshape(-1,1)))[0]\n",
    "        pdf = pdf * (1-p0-p1)\n",
    "        return pdf\n",
    "    \n",
    "class Sim:\n",
    "\n",
    "    def __init__(self, comparison, r_total, max_ibd_segment, n_segment_count):\n",
    "        self.comparison = comparison\n",
    "        self.s1 = comparison.split(':')[0]\n",
    "        self.s2 = comparison.split(':')[1]\n",
    "        \n",
    "        self.r_total = r_total\n",
    "\n",
    "        self.max_ibd_segment = max_ibd_segment\n",
    "        self.n_segment_count = n_segment_count\n",
    "        self.calc_all_likelihoods()\n",
    "        self.max_ll_categorization = max(self.complete_likelihoods,key=self.complete_likelihoods.get)\n",
    "        \n",
    "    def likelihood(self, G, r_flag = 1, ibdmax_flag = 1, count_flag = 1):\n",
    "        r_total_beta_params = pdfs['r_beta'][G]\n",
    "        logL = 0\n",
    "        P_rtotal = scipy.stats.beta.logpdf(self.r_total, *r_total_beta_params)\n",
    "        P_ibdmax = 0\n",
    "        P_seg_count = 0\n",
    "        for chrom in range(1,15):\n",
    "            idx = chrom - 1\n",
    "            P_ibdmax += np.log(evaluate_max_segment_piecewise_pdf(self.max_ibd_segment[idx], G, chrom, \\\n",
    "                                                            pdfs['p_max_segment']))\n",
    "\n",
    "            n_segments = self.n_segment_count[idx]\n",
    "            if n_segments in pdfs['segment_count'][G][str(chrom)].keys():\n",
    "                P_seg_count += np.log(pdfs['segment_count'][G][str(chrom)][n_segments])\n",
    "            else:\n",
    "                P_seg_count += np.log(pdfs['segment_count'][G][str(chrom)]['misc'])\n",
    "        logL = P_rtotal * r_flag +  P_ibdmax * ibdmax_flag + P_seg_count * count_flag\n",
    "\n",
    "        return logL\n",
    "    \n",
    "    def calc_all_likelihoods(self, r_flag = 1, ibdmax_flag = 1, count_flag = 1):\n",
    "        self.complete_likelihoods = {}\n",
    "        self.r_likelihoods = {}\n",
    "        \n",
    "        self.complete_likelihoods_ms = {}\n",
    "        self.r_likelihoods_ms = {}\n",
    "\n",
    "        for G in ['PC', 'GC', 'GGC', 'FS', 'HS', 'FAV', 'HAV', 'FCS']:#, 'MS.MS', 'FAV.MS', 'FCS.MS']:\n",
    "            self.complete_likelihoods[G] = self.likelihood(G, r_flag, ibdmax_flag, count_flag)\n",
    "            self.r_likelihoods[G] = self.likelihood(G, 1, 0, 0)\n",
    "        for G in ['PC', 'GC', 'GGC', 'FS', 'HS', 'FAV', 'HAV', 'FCS','MS.MS', 'FAV.MS', 'FCS.MS']:\n",
    "            self.complete_likelihoods_ms[G] = self.likelihood(G, r_flag, ibdmax_flag, count_flag)\n",
    "            self.r_likelihoods_ms[G] = self.likelihood(G, r_flag, ibdmax_flag, count_flag)\n",
    "        \n",
    "        if self.r_total <= 0.05:\n",
    "            self.max_ll = 'unrelated'\n",
    "        elif self.r_total >= 0.95:\n",
    "            self.max_ll = 'clone'\n",
    "        else:\n",
    "            self.max_ll = max(self.complete_likelihoods,key=self.complete_likelihoods.get)\n",
    "        \n",
    "            \n",
    "def format_ingest_data(file):\n",
    "    data_dict = defaultdict(list)\n",
    "    df = DataFrame(read_csv(file, sep = '\\t'))\n",
    "    data = df.to_numpy()\n",
    "    n_ibd_segment_dict = {}\n",
    "    max_ibd_segment_dict = {}\n",
    "    for row in data:\n",
    "        comparison = row[0]\n",
    "        relatedness = row[1]\n",
    "        n_ibd_segments = row[2:16]\n",
    "        max_ibd_segments = row[16:]\n",
    "        #for chrom, n_ibd, max_ibd in zip(range(1,15), n_ibd_segments, max_ibd_segments):\n",
    "        #    n_ibd_segment_dict[chrom] = n_ibd\n",
    "        #    max_ibd_segment_dict[chrom] = max_ibd\n",
    "        print(comparison)\n",
    "        S = Sim(comparison, relatedness,max_ibd_segments, n_ibd_segments)\n",
    "        data_dict['unknown'].append(S)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b2b0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1:s2\n",
      "s2:s3\n",
      "s4:s5\n",
      "s6:s7\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "data['input'] = format_ingest_data('example_input.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07cdb96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3345b1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e736d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
